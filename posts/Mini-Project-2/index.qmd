---
title: "Mini Project 2"
date: "02-19-2025"
author: "Clayton Fogler"
---

“All work presented is my own, and I have followed all rules for collaboration. I have not used generative AI on this project”

## While in the off-season, coach Puck of the St. Lawrence Football team came up to me with a predicament. He wanted me to try to find how many games we could expect to win this upcoming season. Being someone who loves football and statistics, this was a no brainer for me. To find out this answer, I figured I could use a binomial distribution to figure out whether a team would either win or lose the game. Our random variable, x, would be the number of games the St. Lawrence Football Team will win in a 10-game season, our n will be 10 (for the number of trials or games in a season), but our p (probability of the team winning a single game) is an unknown parameter. This is an issue, but we can solve it by using a maximum likelihood estimation to find an estimator for our p. First, we will take a random sample of 3 10 game seasons from the last 15 10 game seasons played by the Saints, with x representing the number of games won in that season. This sample will be independent and identically distributed. Next, we will find the likelihood function of a binomial distribution X1, X2, X3 i.i.d \~ Binom(n = 10, p). We will use the maximum likelihood estimation (MLE) to derive an estimator for our unknown p. When we do all the steps associated with MLE, we will get the MLE for our P. When we plug in our random sample, we will now how an estimate for our p. While it would be very easy to say “Yeah! We found our p and can now estimate how many games we will win this year”, what we don’t know is if this is the best estimator. To help with this, we can use a different estimator method and use the Method of Moments Estimators (MOM). After doing the steps associated with the MOM, we will now have two different estimators, the Pmle, and Pmom. Now the question is which one is better? To discover this, we can find each estimator's bias, variance, and consistency. Bias will tell us how far off the expectation of our estimator is for p from the actual p. Generally, you want an estimator that is unbiased. Next, we can look at the variance of our estimators. If both of our estimators are unbiased, then we can use variance to see which estimator is more efficient than the other. Generally speaking, we want an estimator that is unbiased and has a high efficiency compared to the other estimator. Finally, we can look to see whether the estimators are consistent. To be consistent, the estimator must be asymptotically unbiased, and its variance must converge to 0. After all these steps, we will find a very strong estimator to answer the question of how many games the St. Lawrence Football team will win this year.
